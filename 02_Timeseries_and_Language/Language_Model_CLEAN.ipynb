{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b657b7a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d13b639f",
   "metadata": {},
   "source": [
    "# Ustvarimo lasten model in ga uƒçimo na podatkih "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95e4e77",
   "metadata": {},
   "source": [
    "## Problem formulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7abc09",
   "metadata": {},
   "source": [
    "# Data preperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "43ef9c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e04bf91b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3522 entries, 0 to 3521\n",
      "Data columns (total 4 columns):\n",
      " #   Column           Non-Null Count  Dtype         \n",
      "---  ------           --------------  -----         \n",
      " 0   patent_abstract  3522 non-null   object        \n",
      " 1   patent_date      3522 non-null   datetime64[ns]\n",
      " 2   patent_number    3522 non-null   object        \n",
      " 3   patent_title     3522 non-null   object        \n",
      "dtypes: datetime64[ns](1), object(3)\n",
      "memory usage: 110.2+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patent_abstract</th>\n",
       "      <th>patent_date</th>\n",
       "      <th>patent_number</th>\n",
       "      <th>patent_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\" A \"\"Barometer\"\" Neuron enhances stability in...</td>\n",
       "      <td>1996-07-09</td>\n",
       "      <td>5535303</td>\n",
       "      <td>\"\"\"Barometer\"\" neuron for a neural network\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\" This invention is a novel high-speed neural ...</td>\n",
       "      <td>1993-10-19</td>\n",
       "      <td>5255349</td>\n",
       "      <td>\"Electronic neural network for solving \"\"trave...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>An optical information processor for use as a ...</td>\n",
       "      <td>1995-01-17</td>\n",
       "      <td>5383042</td>\n",
       "      <td>3 layer liquid crystal neural network with out...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A method and system for intelligent control of...</td>\n",
       "      <td>2001-01-02</td>\n",
       "      <td>6169981</td>\n",
       "      <td>3-brain architecture for an intelligent decisi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A method and system for intelligent control of...</td>\n",
       "      <td>2003-06-17</td>\n",
       "      <td>6581048</td>\n",
       "      <td>3-brain architecture for an intelligent decisi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     patent_abstract patent_date  \\\n",
       "0  \" A \"\"Barometer\"\" Neuron enhances stability in...  1996-07-09   \n",
       "1  \" This invention is a novel high-speed neural ...  1993-10-19   \n",
       "2  An optical information processor for use as a ...  1995-01-17   \n",
       "3  A method and system for intelligent control of...  2001-01-02   \n",
       "4  A method and system for intelligent control of...  2003-06-17   \n",
       "\n",
       "  patent_number                                       patent_title  \n",
       "0       5535303        \"\"\"Barometer\"\" neuron for a neural network\"  \n",
       "1       5255349  \"Electronic neural network for solving \"\"trave...  \n",
       "2       5383042  3 layer liquid crystal neural network with out...  \n",
       "3       6169981  3-brain architecture for an intelligent decisi...  \n",
       "4       6581048  3-brain architecture for an intelligent decisi...  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"./data/neural_network_patent_query.csv\", parse_dates=['patent_date']).dropna(subset = ['patent_abstract'])\n",
    "print(data.info())\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4ff4a54a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "41aa168f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "def preprocess_data(abstracts):\n",
    "    abstracts = abstracts.str.replace(r'(?<=[^\\s0-9])(?=[.,;?])', r' ', regex=True)\n",
    "    abstracts = abstracts.str.replace(r'\\((\\d+)\\)', r'', regex=True)\n",
    "    abstracts = abstracts.str.replace(r'\\s\\s', ' ', regex=True)\n",
    "    \n",
    "    lower=False\n",
    "    filters='!\"%;[\\\\]^_`{|}~\\t\\n'\n",
    "    # Create the tokenizer object and train on texts\n",
    "    tokenizer = Tokenizer(lower=lower, \n",
    "                          filters=filters, \n",
    "                          split=\" \")\n",
    "    tokenizer.fit_on_texts(abstracts.values)\n",
    "    \n",
    "    return abstracts, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b6a2d93f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 16192 unique words.\n"
     ]
    }
   ],
   "source": [
    "abstracts, tokenizer = preprocess_data(data[\"patent_abstract\"])\n",
    "\n",
    "# Create look-up dictionaries and reverse look-ups\n",
    "word_idx = tokenizer.word_index\n",
    "idx_word = tokenizer.index_word\n",
    "num_words = len(word_idx) + 1\n",
    "word_counts = tokenizer.word_counts\n",
    "\n",
    "print(f'There are {num_words} unique words.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "85e251fe",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 the\n",
      "2 a\n",
      "3 of\n",
      "4 .\n",
      "5 ,\n",
      "6 and\n",
      "7 to\n",
      "8 network\n",
      "9 neural\n",
      "10 is\n"
     ]
    }
   ],
   "source": [
    "for i, word in idx_word.items():\n",
    "    if i > 10:\n",
    "        break\n",
    "    print(i, word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "86946803",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(abstracts, tokenizer):\n",
    "    # Convert text to sequences of integers\n",
    "    sequences = tokenizer.texts_to_sequences(abstracts.values)\n",
    "    \n",
    "    return sequences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e677c64c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18, 6149, 3599, 3136, 2003, 12, 2, 426, 683, 1311, 28, 5, 154, 54, 27, 2, 9984, 20, 5, 2976, 102, 9985, 7, 193, 1425, 780, 12, 2, 9986, 1935, 1537, 4, 13, 6149, 3599, 213, 27, 2, 9987, 23, 224, 20, 118, 28, 9988, 2, 5259, 4208, 6, 1425, 7, 2, 1018, 337, 27, 2, 4685, 3600, 3, 4208, 6, 1425, 25, 84, 2, 9989, 225, 3, 3358, 4, 13, 6149, 3599, 2337, 7, 1, 1311, 90, 5, 1289, 283, 90, 1093, 1, 225, 3, 3358, 3, 1, 4685, 472, 5, 6, 203, 2, 519, 1312, 23, 3358, 22, 30, 7, 1, 1311, 25, 1578, 1, 1311, 7, 2, 169, 53, 35, 23, 1217, 7479, 173, 1, 224, 225, 3, 3358, 3, 1, 4685, 472, 4]\n"
     ]
    }
   ],
   "source": [
    "print(create_sequences(abstracts, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "538bf991",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A Barometer Neuron enhances stability in a Neural Network System that , when used as a track-while-scan system , assigns sensor plots to predicted track positions in a plot/track association situation . The Barometer Neuron functions as a bench-mark or reference system node that equates a superimposed plot and track to a zero distance as a perfect pairing of plot and track which has a measured/desired level of inhibition . The Barometer Neuron responds to the System inputs , compares these inputs against the level of inhibition of the perfect pair , and generates a supplied excitation or inhibition output signal to the System which adjusts the System to a desired value at or near 1.0 this the reference level of inhibition of the perfect pair .'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" \".join(tokenizer.index_word[i] for i in create_sequences(abstracts, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "023c4cc5",
   "metadata": {},
   "source": [
    "## Features and Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "67bd88af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vvvvv     HERE     vvvvv\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "def create_features_labels(abstracts, tokenizer, training_length):\n",
    "    # ^^^^^     HERE     ^^^^^\n",
    "    \n",
    "    # Convert text to sequences of integers\n",
    "    sequences = tokenizer.texts_to_sequences(abstracts.values)\n",
    "    \n",
    "    # vvvvv     HERE     vvvvv\n",
    "\n",
    "    # Limit to sequences with more than training length tokens   \n",
    "    sequences_filtered = [x for x in sequences if len(x) > (training_length + 1)]\n",
    "\n",
    "    features = []\n",
    "    labels = []\n",
    "\n",
    "    # Iterate through the sequences of tokens\n",
    "    for seq in sequences_filtered:\n",
    "\n",
    "        # Create multiple training examples from each sequence\n",
    "        for i in range(training_length, len(seq)):\n",
    "            # Extract the features and label\n",
    "            extract = seq[i - training_length: i + 1]\n",
    "\n",
    "            # Set the features and label\n",
    "            features.append(extract[:-1])\n",
    "            labels.append(extract[-1])\n",
    "\n",
    "    print(f'There are {len(features)} sequences.')\n",
    "    \n",
    "    # Randomly shuffle features and labels\n",
    "    features, labels = shuffle(features, labels, random_state=2000)\n",
    "    # ^^^^^     HERE     ^^^^^"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c6563e11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 320713 sequences.\n"
     ]
    }
   ],
   "source": [
    "training_length = 50\n",
    "create_features_labels(abstracts, tokenizer, training_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d73a4d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "# vvvvv     HERE     vvvvv\n",
    "import numpy as np\n",
    "\n",
    "def create_train_valid_sets(abstracts, tokenizer, training_length, train_fraction, num_words):\n",
    "    # ^^^^^     HERE     ^^^^^\n",
    "    \n",
    "    # Convert text to sequences of integers\n",
    "    sequences = tokenizer.texts_to_sequences(abstracts.values)\n",
    "\n",
    "    # Limit to sequences with more than training length tokens   \n",
    "    sequences_filtered = [x for x in sequences if len(x) > (training_length + 20)]\n",
    "\n",
    "    features = []\n",
    "    labels = []\n",
    "\n",
    "    # Iterate through the sequences of tokens\n",
    "    for seq in sequences_filtered:\n",
    "\n",
    "        # Create multiple training examples from each sequence\n",
    "        for i in range(training_length, len(seq)):\n",
    "            # Extract the features and label\n",
    "            extract = seq[i - training_length: i + 1]\n",
    "\n",
    "            # Set the features and label\n",
    "            features.append(extract[:-1])\n",
    "            labels.append(extract[-1])\n",
    "\n",
    "    print(f'There are {len(features)} sequences.')\n",
    "    \n",
    "    # Randomly shuffle features and labels\n",
    "    features, labels = shuffle(features, labels, random_state=2000)\n",
    "\n",
    "    # vvvvv     HERE     vvvvv\n",
    "    # Decide on number of samples for training\n",
    "    train_end = int(train_fraction * len(labels))\n",
    "    X_train = np.array(features[:train_end]) \n",
    "    X_valid = np.array(features[train_end:])\n",
    "    \n",
    "    # Empty array to hold labels\n",
    "    label_array = np.zeros((len(labels), num_words), dtype=np.int8) # use int8 to save memory!\n",
    "\n",
    "    # One hot encode the labels\n",
    "    for example_index, word_index in enumerate(labels):\n",
    "        label_array[example_index, word_index] = 1\n",
    "\n",
    "    labels = label_array\n",
    "    # TO find the word\n",
    "    tokenizer.index_word[np.argmax(labels[0])]\n",
    "    \n",
    "    y_train = np.array(labels[:train_end])\n",
    "    y_valid = np.array(labels[train_end:])\n",
    "    \n",
    "    return X_train, X_valid, y_train, y_valid\n",
    "    # ^^^^^     HERE     ^^^^^"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d1235a12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 318563 sequences.\n"
     ]
    }
   ],
   "source": [
    "training_length=50\n",
    "train_fraction = 0.7\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = create_train_valid_sets(abstracts, tokenizer, training_length, train_fraction, num_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5f215fcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: based , at least in part , upon the health status of the welder , welder data , an expert data store , a local service support data store , a remote expert data store and/or a remote service support data store . The expert component can employ various artificial\n",
      "\n",
      "Label: intelligence\n",
      "\n"
     ]
    }
   ],
   "source": [
    "seq_id = 0\n",
    "sequence = X_train[seq_id]\n",
    "text = []\n",
    "for idx in sequence:\n",
    "    text.append(idx_word[idx])\n",
    "        \n",
    "print('Features: ' + ' '.join(text) + '\\n')\n",
    "print('Label: ' + idx_word[np.argmax(y_train[seq_id])] + '\\n')    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936f047e",
   "metadata": {},
   "source": [
    "# Creating a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a7535610",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout, Masking, Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d59e26fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 50, 100)           1619200   \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 64)                42240     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 16192)             1052480   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,718,080\n",
      "Trainable params: 1,098,880\n",
      "Non-trainable params: 1,619,200\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# Embedding layer\n",
    "model.add(\n",
    "    Embedding(input_dim=num_words,\n",
    "              input_length = training_length,\n",
    "              output_dim=100,\n",
    "              trainable=False))\n",
    "\n",
    "# Recurrent layer\n",
    "model.add(LSTM(64, return_sequences=False, \n",
    "               dropout=0.1, recurrent_dropout=0.1))\n",
    "\n",
    "# Fully connected layer\n",
    "model.add(Dense(64, activation='relu'))\n",
    "\n",
    "# Dropout for regularization\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# Output layer\n",
    "model.add(Dense(num_words, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5053a817",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "10/10 [==============================] - 2s 42ms/step - loss: 9.6885 - accuracy: 0.0267\n",
      "Epoch 2/3\n",
      "10/10 [==============================] - 0s 45ms/step - loss: 9.6560 - accuracy: 0.0733\n",
      "Epoch 3/3\n",
      "10/10 [==============================] - 0s 44ms/step - loss: 9.1997 - accuracy: 0.0600\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train[:300],  y_train[:300],\n",
    "                    verbose=1,\n",
    "                    epochs=3,\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be6a4fc",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "071d65f0",
   "metadata": {},
   "source": [
    "## Pre-trained Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b9e2e21",
   "metadata": {},
   "source": [
    "GloVe - http://nlp.stanford.edu/data/glove.6B.zip (822MB)\n",
    "* glove.6B.100d.txt je velik 348MB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd8f6d7c",
   "metadata": {},
   "source": [
    "```python\n",
    "import numpy as np\n",
    "\n",
    "# Load in embeddings\n",
    "glove_vectors = './models/glove.6B.100d.txt'\n",
    "glove = np.loadtxt(glove_vectors, dtype='str', comments=None)\n",
    "\n",
    "# Extract the vectors and words\n",
    "vectors = glove[:, 1:].astype('float')\n",
    "words = glove[:, 0]\n",
    "\n",
    "# Create lookup of words to vectors\n",
    "word_lookup = {word: vector for word, vector in zip(words, vectors)}\n",
    "\n",
    "# New matrix to hold word embeddings\n",
    "embedding_matrix = np.zeros((num_words, vectors.shape[1]))\n",
    "\n",
    "for i, word in enumerate(word_idx.keys()):\n",
    "    # Look up the word embedding\n",
    "    vector = word_lookup.get(word, None)\n",
    "\n",
    "    # Record in matrix\n",
    "    if vector is not None:\n",
    "        embedding_matrix[i + 1, :] = vector\n",
    "        \n",
    "# Look a word up\n",
    "word_lookup[\"neural\"][:10]\n",
    "        \n",
    "#...\n",
    "model.add(\n",
    "    Embedding(input_dim=num_words,\n",
    "              input_length = training_length,\n",
    "              output_dim=100,\n",
    "              weights=[embedding_matrix],\n",
    "              trainable=False,\n",
    "              mask_zero=True))\n",
    "\n",
    "# Masking layer for pre-trained embeddings\n",
    "model.add(Masking(mask_value=0.0))\n",
    "#...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "7f543947",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9cbe2b20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (None, None, 100)         1619200   \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 64)                42240     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 128)               8320      \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 16192)             2088768   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,758,528\n",
      "Trainable params: 3,758,528\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = load_model('./models/train-embeddings-rnn.h5')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "bde2763e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Performance: Log Loss and Accuracy on validation data\n",
      "313/313 [==============================] - 4s 13ms/step - loss: 3.8490 - accuracy: 0.3106\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3.8489832878112793, 0.31060001254081726]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('\\nModel Performance: Log Loss and Accuracy on validation data')\n",
    "model.evaluate(X_valid[:10_000], y_valid[:10_000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ad17a08a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: based , at least in part , upon the health status of the welder , welder data , an expert data store , a local service support data store , a remote expert data store and/or a remote service support data store . The expert component can employ various artificial\n",
      "\n",
      "1/1 [==============================] - 0s 255ms/step\n",
      "Next word:  neural\n"
     ]
    }
   ],
   "source": [
    "seq_id = 0\n",
    "sequence = X_train[seq_id]\n",
    "text = []\n",
    "\n",
    "for idx in sequence:\n",
    "    text.append(idx_word[idx])\n",
    "        \n",
    "print('Features: ' + ' '.join(text) + '\\n')\n",
    "\n",
    "# Make prediction\n",
    "prediction = model.predict(np.reshape(sequence, newshape=(1,-1)))[0]\n",
    "\n",
    "# Prediction to text\n",
    "print(\"Next word: \", idx_word[np.argmax(prediction)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "cda23eed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "wafer using the reticle and determining a transfer of at least one of said plurality of pattern features from said reticle to said wafer . Preferably , a neural network is trained using the determination . Preferably , a reticle is inspected by running detected defects through the neural network   =>  . The system is used to determine the querying device . The neural network is trained to determine the system . The system is used to train the neural network\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from collections import deque\n",
    "\n",
    "seq_id = 10\n",
    "sequence = deque(X_train[seq_id], maxlen=X_train[0].shape[0])\n",
    "text = []\n",
    "\n",
    "for idx in sequence:\n",
    "    text.append(idx_word[idx])\n",
    "text.append(\"  => \")        \n",
    "\n",
    "text_length = 30\n",
    "for _ in range(text_length):\n",
    "    # Make prediction\n",
    "    prediction = model.predict(np.reshape(sequence, newshape=(1,-1)),)[0]\n",
    "\n",
    "    # Choose new word\n",
    "    word_id = np.argmax(prediction)\n",
    "    \n",
    "    # Prediction to text\n",
    "    new_word = idx_word[word_id]\n",
    "    text.append(new_word)\n",
    "    \n",
    "    # Update sequence\n",
    "    sequence.append(word_id)\n",
    "\n",
    "\n",
    "print(' '.join(text) + '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "2617aa56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot: >"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "my_preds = [0.5, 0.1, 0.2, 0.2]\n",
    "my_words = [\"Hello\", \"World\", \"Python\", \"AI\"]\n",
    "\n",
    "my_res = np.random.choice(my_words, size=10_000, p=my_preds)\n",
    "pd.Series(my_res).value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "0e07372d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "wafer using the reticle and determining a transfer of at least one of said plurality of pattern features from said reticle to said wafer . Preferably , a neural network is trained using the determination . Preferably , a reticle is inspected by running detected defects through the neural network   =>  to each input region which can be based which can be segmented in a variety of sticky , olefins , such , dopamine neurotrophic tomography\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from collections import deque\n",
    "\n",
    "seq_id = 10\n",
    "sequence = deque(X_train[seq_id], maxlen=X_train[0].shape[0])\n",
    "text = []\n",
    "\n",
    "for idx in sequence:\n",
    "    text.append(idx_word[idx])\n",
    "text.append(\"  => \")        \n",
    "\n",
    "text_length = 25\n",
    "for _ in range(text_length):\n",
    "    # Make prediction\n",
    "    prediction = model.predict(np.reshape(sequence, newshape=(1,-1)),)[0]\n",
    "\n",
    "    # Choose new word\n",
    "    word_value = np.random.choice(prediction, p=prediction)\n",
    "    word_id = np.where(prediction == word_value)[0][0]\n",
    "    \n",
    "    # Prediction to text\n",
    "    new_word = idx_word[word_id]\n",
    "    text.append(new_word)\n",
    "    \n",
    "    # Update sequence\n",
    "    sequence.append(word_id)\n",
    "\n",
    "\n",
    "print(' '.join(text) + '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "a476d75b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 196ms/step\n",
      "1/1 [==============================] - 0s 187ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "This patent provides a way of using neural-network as task management system   =>  on a Host application . The preferred embodiment is used to simulate usage information prior to molecules beyond an enhanced image and vision , head\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from collections import deque\n",
    "\n",
    "prompt = \"This patent provides a way of using neural-network as task management system\"\n",
    "tokenized_seq = tokenizer.texts_to_sequences([prompt])\n",
    "sequence = deque(tokenized_seq[0], maxlen=50)\n",
    "text = []\n",
    "\n",
    "for idx in sequence:\n",
    "    text.append(idx_word[idx])\n",
    "text.append(\"  => \")    \n",
    "\n",
    "text_length = 25\n",
    "for _ in range(text_length):\n",
    "    # Make prediction\n",
    "    prediction = model.predict(np.reshape(sequence, newshape=(1,-1)),)[0]\n",
    "\n",
    "    # Choose new word\n",
    "    word_value = np.random.choice(prediction, p=prediction)\n",
    "    word_id = np.where(prediction == word_value)[0][0]\n",
    "    \n",
    "    # Prediction to text\n",
    "    new_word = idx_word[word_id]\n",
    "    text.append(new_word)\n",
    "    \n",
    "    # Update sequence\n",
    "    sequence.append(word_id)\n",
    "\n",
    "\n",
    "print(' '.join(text) + '\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb0e5cc9",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e54e17",
   "metadata": {},
   "source": [
    "# ChatGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "adce6424",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "b77405f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and set our key\n",
    "openai.api_key = open(\"../../openai_API.txt\", \"r\").read().strip(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b8c179",
   "metadata": {},
   "source": [
    "Cenik je trenutno:\n",
    "* GPT-3.5 - $0.002 / 1K tokens\n",
    "\n",
    "https://openai.com/pricing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "a30f6d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "completion = openai.ChatCompletion.create(\n",
    "  model=\"gpt-3.5-turbo\", # this is \"ChatGPT\" $0.002 per 1k tokens\n",
    "  messages=[{\"role\": \"user\", \"content\": \"What is the circumference in km of the planet Earth?\"}]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "e6180798",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject chat.completion id=chatcmpl-74Tn7rOxKqfUpWxPpxf2xG4z2hiFP at 0x28633c620c0> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"finish_reason\": \"stop\",\n",
       "      \"index\": 0,\n",
       "      \"message\": {\n",
       "        \"content\": \"The circumference of the Earth is approximately 40,075 km.\",\n",
       "        \"role\": \"assistant\"\n",
       "      }\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1681302185,\n",
       "  \"id\": \"chatcmpl-74Tn7rOxKqfUpWxPpxf2xG4z2hiFP\",\n",
       "  \"model\": \"gpt-3.5-turbo-0301\",\n",
       "  \"object\": \"chat.completion\",\n",
       "  \"usage\": {\n",
       "    \"completion_tokens\": 13,\n",
       "    \"prompt_tokens\": 19,\n",
       "    \"total_tokens\": 32\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "6437af67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The circumference of the Earth is approximately 40,075 km.\n"
     ]
    }
   ],
   "source": [
    "reply_content = completion.choices[0].message.content\n",
    "print(reply_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "dca30483",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject chat.completion id=chatcmpl-74UEyknDTUj46fraDX5O0fm9PtqIo at 0x28633c54f90> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"finish_reason\": \"stop\",\n",
       "      \"index\": 0,\n",
       "      \"message\": {\n",
       "        \"content\": \"to increase efficiency and productivity in various industries - including but not limited to healthcare, logistics, and manufacturing. By using machine learning algorithms, the system adapts to changing circumstances and assigns tasks to the most suitable individuals, providing real-time monitoring and tracking capabilities. This system can help businesses optimize their workflows, reduce errors and delays, and ultimately improve their bottom line.\",\n",
       "        \"role\": \"assistant\"\n",
       "      }\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1681303912,\n",
       "  \"id\": \"chatcmpl-74UEyknDTUj46fraDX5O0fm9PtqIo\",\n",
       "  \"model\": \"gpt-3.5-turbo-0301\",\n",
       "  \"object\": \"chat.completion\",\n",
       "  \"usage\": {\n",
       "    \"completion_tokens\": 72,\n",
       "    \"prompt_tokens\": 42,\n",
       "    \"total_tokens\": 114\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completion = openai.ChatCompletion.create(\n",
    "  model=\"gpt-3.5-turbo\", # this is \"ChatGPT\" $0.002 per 1k tokens\n",
    "  messages=[\n",
    "      {\"role\": \"system\", \"content\": \"You are writting a patent. It must contain maximum of 100 words.\"},\n",
    "      {\"role\": \"user\", \"content\": \"This patent provides a way of using neural-network as task management system\"}]\n",
    ")\n",
    "\n",
    "completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "d7f0926d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "to increase efficiency and productivity in various industries - including but not limited to healthcare, logistics, and manufacturing. By using machine learning algorithms, the system adapts to changing circumstances and assigns tasks to the most suitable individuals, providing real-time monitoring and tracking capabilities. This system can help businesses optimize their workflows, reduce errors and delays, and ultimately improve their bottom line.\n"
     ]
    }
   ],
   "source": [
    "reply_content = completion.choices[0].message.content\n",
    "print(reply_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5df971a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "cd46690a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> What is circumeference of Earth?\n",
      "User's input was:  What is circumeference of Earth?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'role': 'user', 'content': 'What is circumeference of Earth?'}]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message_history = []\n",
    "# What is the moon's circumference in km?\n",
    "user_input = input(\"> \")\n",
    "print(\"User's input was: \", user_input)\n",
    "\n",
    "message_history.append({\"role\": \"user\", \"content\": f\"{user_input}\"})\n",
    "message_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "5727ca87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The circumference of Earth is approximately 40,075 km (24,901 mi).\n"
     ]
    }
   ],
   "source": [
    "completion = openai.ChatCompletion.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=message_history\n",
    ")\n",
    "\n",
    "# Now we can print the response:\n",
    "reply_content = completion.choices[0].message.content\n",
    "print(reply_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "585d8d5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user', 'content': 'What is circumeference of Earth?'},\n",
       " {'role': 'assistant',\n",
       "  'content': 'The circumference of Earth is approximately 40,075 km (24,901 mi).'}]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# note the use of the \"assistant\" role here. This is because we're feeding the model's response into context.\n",
    "message_history.append({\"role\": \"assistant\", \"content\": f\"{reply_content}\"})\n",
    "message_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "7b1198f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> which moon is that in reference to?\n",
      "User's input was:  which moon is that in reference to?\n",
      "\n",
      "I apologize for the error in my previous response. The circumference of Earth is not in reference to any moon. Earth is the planet that has a circumference of approximately 40,075 km (24,901 mi).\n"
     ]
    }
   ],
   "source": [
    "# which moon is that in reference to?\n",
    "user_input = input(\"> \")\n",
    "print(\"User's input was: \", user_input)\n",
    "print()\n",
    "message_history.append({\"role\": \"user\", \"content\": f\"{user_input}\"})\n",
    "\n",
    "completion = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=message_history\n",
    ")\n",
    "\n",
    "reply_content = completion.choices[0].message.content\n",
    "print(reply_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "194589fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Can I drink the water from a dehumidifier?\n",
      "User's input was:  Can I drink the water from a dehumidifier?\n",
      "No, it is not safe to drink water from a dehumidifier. The water collected by a dehumidifier is not potable and can contain impurities, bacteria, and other harmful substances. It is recommended to dispose of this water properly and not use it for any purpose other than draining or cleaning the dehumidifier.\n",
      "\n",
      "> Can I drink the water from a dehumidifier?\n",
      "User's input was:  Can I drink the water from a dehumidifier?\n",
      "As an AI language model, I'm an AI digital assistant and I do not have a personal opinion. However, I can inform you that it is not safe to drink the water from a dehumidifier. Although the water may appear clean, it can contain impurities, bacteria, and other harmful substances that can cause health problems. It is advisable to dispose of this water properly and not use it for any purpose other than draining or cleaning the dehumidifier. If you need drinking water, it is best to get it from a safe and reliable source such as a water filter or a public water system.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "message_history = []\n",
    "\n",
    "def chat(inp, role=\"user\"):\n",
    "    message_history.append({\"role\": role, \"content\": f\"{inp}\"})\n",
    "    completion = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=message_history\n",
    "    )\n",
    "    reply_content = completion.choices[0].message.content\n",
    "    message_history.append({\"role\": \"assistant\", \"content\": f\"{reply_content}\"})\n",
    "    return reply_content\n",
    "\n",
    "for i in range(2):\n",
    "    user_input = input(\"> \")\n",
    "    print(\"User's input was: \", user_input)\n",
    "    print(chat(user_input))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d2bca8",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd86404",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3400fc40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0ce8fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c98283",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b9157b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
